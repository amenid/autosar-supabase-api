import torch
import os
import time
import streamlit as st
import json
import base64
import hashlib
import hmac
import secrets
import ssl
import socket
import smtplib
import requests
from requests.auth import HTTPBasicAuth
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from datetime import datetime, timedelta
from dotenv import load_dotenv

# Nouveaux imports pour RAG
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
import pickle
from pathlib import Path
import PyPDF2
import docx
from typing import List, Dict, Any, Optional
import re

# Imports pour s√©curit√© avanc√©e
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes, serialization
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
from cryptography.hazmat.primitives.asymmetric import rsa, padding
from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes
from cryptography.hazmat.backends import default_backend
from cryptography import x509
from cryptography.x509.oid import NameOID
import html
import urllib.parse

# Imports manquants √† ajouter
import sqlite3
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

load_dotenv()

class DocumentChunk:
    """Repr√©sente un chunk de document avec m√©tadonn√©es"""
    def __init__(self, content: str, metadata: dict):
        self.content = content
        self.metadata = metadata
        self.properties = metadata  # Pour compatibilit√© avec le code existant

class RAGRetriever:
    """Syst√®me RAG complet pour AUTOSAR avec support multi-formats"""
    
    def __init__(self, documents_path: str = "autosar_documents"):
        self.documents_path = Path(documents_path)
        self.documents_path.mkdir(exist_ok=True)
        
        # Mod√®le d'embedding
        print("üîÑ Chargement du mod√®le d'embedding...")
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # Base de donn√©es vectorielle
        self.vector_db_path = "autosar_vectors.faiss"
        self.metadata_path = "autosar_metadata.pkl"
        
        # Chunks et m√©tadonn√©es
        self.chunks = []
        self.chunk_embeddings = None
        self.faiss_index = None
        
        # Initialiser ou charger la base existante
        self._initialize_or_load_database()
        
        print(f"‚úÖ RAG initialis√© avec {len(self.chunks)} chunks")
    
    def _initialize_or_load_database(self):
        """Initialise ou charge la base de donn√©es existante"""
        if os.path.exists(self.vector_db_path) and os.path.exists(self.metadata_path):
            print("üìÇ Chargement de la base vectorielle existante...")
            self._load_existing_database()
        else:
            print("üÜï Cr√©ation d'une nouvelle base vectorielle...")
            self._create_sample_autosar_content()
            self._build_vector_database()
    
    def _load_existing_database(self):
        """Charge la base vectorielle existante"""
        try:
            # Charger l'index FAISS
            self.faiss_index = faiss.read_index(self.vector_db_path)
            
            # Charger les m√©tadonn√©es
            with open(self.metadata_path, 'rb') as f:
                self.chunks = pickle.load(f)
            
            print(f"‚úÖ Base vectorielle charg√©e: {len(self.chunks)} chunks")
            
        except Exception as e:
            print(f"‚ùå Erreur chargement base: {e}")
            self._create_sample_autosar_content()
            self._build_vector_database()
    
    def _create_sample_autosar_content(self):
        """Cr√©e du contenu AUTOSAR de d√©monstration"""
        sample_content = {
            "AUTOSAR_Architecture_Overview.txt": """
AUTOSAR (AUTomotive Open System ARchitecture) Overview

AUTOSAR is a global partnership of automotive manufacturers, suppliers, and other companies from the electronics, semiconductor and software industry. The architecture consists of three main layers:

1. Application Layer
- Software Components (SWCs)
- AUTOSAR Runtime Environment (RTE)
- Complex Device Drivers (CDD)

2. Runtime Environment (RTE)
- Communication abstraction
- Service-oriented communication
- Event-driven communication

3. Basic Software (BSW)
- Operating System (OS)
- Communication Stack
- Memory Stack
- I/O Hardware Abstraction

Key Benefits:
- Standardization across automotive industry
- Improved software reusability
- Enhanced modularity and scalability
- Better integration of software components
""",
            
            "AUTOSAR_Communication_Stack.txt": """
AUTOSAR Communication Stack

The AUTOSAR communication stack enables efficient data exchange between ECUs:

1. CAN Communication
- Controller Area Network protocol
- Frame formats: Standard (11-bit) and Extended (29-bit)
- Error handling and arbitration mechanisms

2. Ethernet Communication
- IEEE 802.3 standard support
- TCP/IP and UDP protocols
- Time-sensitive networking (TSN)

3. LIN Communication
- Local Interconnect Network
- Master-slave architecture
- Low-cost communication for non-critical systems

Communication Services:
- Diagnostic Communication Manager (DCM)
- Network Management (NM)
- Communication Security (SecOC)
- Service Discovery (SD)

Protocol Data Units (PDUs):
- I-PDU: Interaction PDU
- N-PDU: Network PDU
- Transport Protocol handling
""",
            
            "RFC_Standards_Integration.txt": """
RFC Standards in AUTOSAR Context

AUTOSAR integrates various RFC standards for communication protocols:

RFC 791 - Internet Protocol (IP)
- IPv4 addressing and routing
- Packet fragmentation and reassembly
- Integration with AUTOSAR Ethernet stack

RFC 793 - Transmission Control Protocol (TCP)
- Reliable, connection-oriented communication
- Flow control and congestion management
- Used in AUTOSAR for diagnostic services

RFC 768 - User Datagram Protocol (UDP)
- Connectionless communication protocol
- Low overhead for real-time applications
- SOME/IP communication over UDP

RFC 2616 - Hypertext Transfer Protocol (HTTP)
- Application layer protocol
- RESTful service interfaces
- Over-the-air (OTA) update mechanisms

RFC 6455 - WebSocket Protocol
- Full-duplex communication
- Real-time data streaming
- Vehicle-to-cloud connectivity

Security RFCs:
- RFC 5246 (TLS 1.2)
- RFC 8446 (TLS 1.3)
- RFC 3280 (PKI Certificate validation)
""",
            
            "AUTOSAR_Methodology.txt": """
AUTOSAR Methodology and Development Process

The AUTOSAR methodology defines a systematic approach for developing automotive software:

1. System Configuration
- System template creation
- ECU configuration
- Network topology definition

2. Software Component Design
- Interface definition
- Behavior modeling
- Component implementation

3. System Integration
- ECU configuration
- Communication matrix
- System validation

4. Code Generation
- Automatic code generation from models
- BSW configuration
- RTE generation

Tools and Artifacts:
- ARXML files for configuration exchange
- System Description (AUTOSAR System Template)
- ECU Configuration (AUTOSAR ECU Template)
- Software Component Template

Development Phases:
- Analysis and Design
- Implementation
- Integration and Testing
- Deployment and Maintenance

Quality Assurance:
- ISO 26262 functional safety compliance
- ASPICE process improvement
- Model-based testing approaches
""",
            
            "AUTOSAR_Security.txt": """
AUTOSAR Security Framework

Cybersecurity is crucial in modern automotive systems:

1. Secure Communication
- Message Authentication Codes (MAC)
- Encryption and decryption services
- Key management infrastructure

2. Secure Boot Process
- Verified boot chain
- Code integrity validation
- Hardware Security Module (HSM) integration

3. Intrusion Detection
- Anomaly detection algorithms
- Network traffic monitoring
- Incident response procedures

Security Modules:
- Cryptographic Service Manager (CSM)
- Secure Onboard Communication (SecOC)
- Key Manager (KeyM)
- Certificate Manager (CertM)

Threat Mitigation:
- Secure software updates
- Access control mechanisms
- Audit logging and monitoring
- Security event management

Compliance Standards:
- ISO/SAE 21434 (Cybersecurity Engineering)
- UN-R155 (Cybersecurity Management System)
- UN-R156 (Software Update Management System)
"""
        }
        
        # Cr√©er les fichiers de d√©monstration
        for filename, content in sample_content.items():
            file_path = self.documents_path / filename
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
        
        print(f"üìù {len(sample_content)} documents AUTOSAR cr√©√©s")
    
    def load_documents(self):
        """Charge tous les documents du r√©pertoire"""
        documents = []
        
        for file_path in self.documents_path.glob("*"):
            if file_path.suffix.lower() in ['.txt', '.pdf', '.docx', '.md']:
                try:
                    content = self._extract_text(file_path)
                    if content.strip():
                        documents.append({
                            'content': content,
                            'source': file_path.name,
                            'path': str(file_path)
                        })
                        print(f"‚úÖ Charg√©: {file_path.name}")
                except Exception as e:
                    print(f"‚ùå Erreur chargement {file_path.name}: {e}")
        
        print(f"üìö {len(documents)} documents charg√©s")
        return documents
    
    def _extract_text(self, file_path: Path) -> str:
        """Extrait le texte selon le type de fichier"""
        if file_path.suffix.lower() == '.txt' or file_path.suffix.lower() == '.md':
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        
        elif file_path.suffix.lower() == '.pdf':
            text = ""
            try:
                with open(file_path, 'rb') as f:
                    reader = PyPDF2.PdfReader(f)
                    for page in reader.pages:
                        text += page.extract_text() + "\n"
            except:
                print(f"‚ö†Ô∏è Erreur lecture PDF: {file_path.name}")
            return text
        
        elif file_path.suffix.lower() == '.docx':
            try:
                doc = docx.Document(file_path)
                text = ""
                for paragraph in doc.paragraphs:
                    text += paragraph.text + "\n"
                return text
            except:
                print(f"‚ö†Ô∏è Erreur lecture DOCX: {file_path.name}")
                return ""
        
        return ""
    
    def create_chunks(self, documents: List[Dict]) -> List[DocumentChunk]:
        """Divise les documents en chunks avec overlap"""
        chunks = []
        chunk_size = 500
        overlap = 50
        
        for doc in documents:
            content = doc['content']
            words = content.split()
            
            for i in range(0, len(words), chunk_size - overlap):
                chunk_words = words[i:i + chunk_size]
                chunk_content = ' '.join(chunk_words)
                
                if len(chunk_content.strip()) > 50:  # Filtrer les chunks trop petits
                    chunk = DocumentChunk(
                        content=chunk_content,
                        metadata={
                            'source': doc['source'],
                            'path': doc['path'],
                            'chunk_index': len(chunks),
                            'word_count': len(chunk_words)
                        }
                    )
                    chunks.append(chunk)
        
        print(f"‚úÇÔ∏è {len(chunks)} chunks cr√©√©s")
        return chunks
    
    def _build_vector_database(self):
        """Construit la base de donn√©es vectorielle"""
        # Charger les documents
        documents = self.load_documents()
        if not documents:
            print("‚ö†Ô∏è Aucun document trouv√©")
            return
        
        # Cr√©er les chunks
        self.chunks = self.create_chunks(documents)
        if not self.chunks:
            print("‚ö†Ô∏è Aucun chunk cr√©√©")
            return
        
        # G√©n√©rer les embeddings
        print("üîÑ G√©n√©ration des embeddings...")
        chunk_texts = [chunk.content for chunk in self.chunks]
        embeddings = self.embedding_model.encode(chunk_texts, show_progress_bar=True)
        
        # Cr√©er l'index FAISS
        dimension = embeddings.shape[1]
        self.faiss_index = faiss.IndexFlatIP(dimension)  # Inner Product pour cosine similarity
        
        # Normaliser pour cosine similarity
        faiss.normalize_L2(embeddings)
        self.faiss_index.add(embeddings.astype('float32'))
        
        # Sauvegarder
        faiss.write_index(self.faiss_index, self.vector_db_path)
        with open(self.metadata_path, 'wb') as f:
            pickle.dump(self.chunks, f)
        
        print(f"üíæ Base vectorielle sauvegard√©e avec {len(self.chunks)} chunks")
    
    def hybrid_search(self, query: str, top_k: int = 5) -> List[DocumentChunk]:
        """Recherche hybride (vectorielle + mot-cl√©s)"""
        if not self.faiss_index or not self.chunks:
            print("‚ö†Ô∏è Base vectorielle non initialis√©e")
            return []
        
        # Recherche vectorielle
        query_embedding = self.embedding_model.encode([query])
        faiss.normalize_L2(query_embedding)
        
        scores, indices = self.faiss_index.search(query_embedding.astype('float32'), top_k * 2)
        
        # R√©cup√©rer les chunks
        vector_results = []
        for score, idx in zip(scores[0], indices[0]):
            if idx < len(self.chunks):
                chunk = self.chunks[idx]
                vector_results.append((chunk, float(score)))
        
        # Recherche par mots-cl√©s
        query_words = set(query.lower().split())
        keyword_results = []
        
        for chunk in self.chunks:
            chunk_words = set(chunk.content.lower().split())
            overlap = len(query_words.intersection(chunk_words))
            if overlap > 0:
                keyword_score = overlap / len(query_words)
                keyword_results.append((chunk, keyword_score))
        
        # Combiner les r√©sultats
        combined_scores = {}
        
        # Ajouter scores vectoriels
        for chunk, score in vector_results:
            chunk_id = id(chunk)
            combined_scores[chunk_id] = {'chunk': chunk, 'vector_score': score, 'keyword_score': 0}
        
        # Ajouter scores mots-cl√©s
        for chunk, score in keyword_results:
            chunk_id = id(chunk)
            if chunk_id in combined_scores:
                combined_scores[chunk_id]['keyword_score'] = score
            else:
                combined_scores[chunk_id] = {'chunk': chunk, 'vector_score': 0, 'keyword_score': score}
        
        # Score final combin√©
        final_results = []
        for data in combined_scores.values():
            final_score = 0.7 * data['vector_score'] + 0.3 * data['keyword_score']
            final_results.append((data['chunk'], final_score))
        
        # Trier par score final
        final_results.sort(key=lambda x: x[1], reverse=True)
        
        return [chunk for chunk, score in final_results[:top_k]]
    
    def generate_answer(self, query: str, chunks: List[DocumentChunk], 
                       model_type: str = "deepseek-r1:7b", api_key: str = None, 
                       temperature: float = 0.3) -> str:
        """G√©n√®re une r√©ponse bas√©e sur les chunks r√©cup√©r√©s"""
        
        if not chunks:
            return "‚ùå Aucun contexte pertinent trouv√© dans la base de connaissances AUTOSAR."
        
        # Construire le contexte
        context = "\n\n".join([
            f"üìÑ **Source: {chunk.metadata['source']}**\n{chunk.content}"
            for chunk in chunks
        ])
        
        # Prompt syst√®me pour AUTOSAR
        system_prompt = """Tu es un expert AUTOSAR (AUTomotive Open System ARchitecture) et des standards RFC. 
        R√©ponds de mani√®re pr√©cise et technique en utilisant UNIQUEMENT les informations fournies dans le contexte.
        
        Instructions:
        - Utilise le contexte fourni pour r√©pondre
        - Cite les sources quand n√©cessaire
        - Sois pr√©cis et technique
        - Si l'information n'est pas dans le contexte, dis-le clairement
        - Formate ta r√©ponse en markdown pour une meilleure lisibilit√©"""
        
        # Prompt utilisateur
        user_prompt = f"""
        **Question:** {query}
        
        **Contexte AUTOSAR disponible:**
        {context}
        
        **R√©ponse d√©taill√©e:**
        """
        
        try:
            if "API Model" in model_type and api_key:
                return self._call_api_model(system_prompt, user_prompt, api_key, temperature)
            else:
                return self._call_ollama_model(system_prompt, user_prompt, model_type, temperature)
        
        except Exception as e:
            print(f"‚ùå Erreur g√©n√©ration r√©ponse: {e}")
            return f"‚ùå Erreur lors de la g√©n√©ration de la r√©ponse: {str(e)}"
    
    def _call_ollama_model(self, system_prompt: str, user_prompt: str, 
                          model: str, temperature: float) -> str:
        """Appelle un mod√®le Ollama local"""
        try:
            import requests
            
            # URL Ollama par d√©faut
            ollama_url = "http://localhost:11434/api/generate"
            
            payload = {
                "model": model,
                "prompt": f"{system_prompt}\n\n{user_prompt}",
                "temperature": temperature,
                "stream": False
            }
            
            response = requests.post(ollama_url, json=payload, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                return result.get('response', 'R√©ponse vide du mod√®le')
            else:
                return f"‚ùå Erreur Ollama ({response.status_code}): Assurez-vous qu'Ollama est d√©marr√© avec `ollama serve`"
        
        except requests.exceptions.ConnectionError:
            return """‚ùå **Impossible de se connecter √† Ollama**
            
            **Solutions:**
            1. Installez Ollama: https://ollama.com/
            2. D√©marrez le service: `ollama serve`
            3. T√©l√©chargez le mod√®le: `ollama pull deepseek-r1:7b`
            4. Ou utilisez un mod√®le API avec votre cl√©"""
        
        except Exception as e:
            return f"‚ùå Erreur inattendue: {str(e)}"
    
    def _call_api_model(self, system_prompt: str, user_prompt: str, 
                       api_key: str, temperature: float) -> str:
        """Appelle un mod√®le via API (Gemini, OpenAI, etc.)"""
        try:
            # Exemple avec Gemini (adaptez selon vos besoins)
            import google.generativeai as genai
            
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-pro')
            
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            response = model.generate_content(full_prompt)
            
            return response.text
        
        except Exception as e:
            return f"‚ùå Erreur API: {str(e)}"
    
    def add_document(self, file_path: str, content: str = None):
        """Ajoute un nouveau document √† la base"""
        try:
            if content is None:
                content = self._extract_text(Path(file_path))
            
            # Cr√©er le fichier
            new_file = self.documents_path / Path(file_path).name
            with open(new_file, 'w', encoding='utf-8') as f:
                f.write(content)
            
            # Reconstruire la base
            self._build_vector_database()
            print(f"‚úÖ Document ajout√©: {Path(file_path).name}")
            
        except Exception as e:
            print(f"‚ùå Erreur ajout document: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques de la base RAG"""
        return {
            'total_chunks': len(self.chunks),
            'total_documents': len(set(chunk.metadata['source'] for chunk in self.chunks)),
            'vector_db_size': os.path.getsize(self.vector_db_path) if os.path.exists(self.vector_db_path) else 0,
            'embedding_model': 'all-MiniLM-L6-v2',
            'documents_path': str(self.documents_path)
        }

# Garder vos classes de s√©curit√© existantes (SecurityFilter, etc.)
class SecurityFilter:
    """Syst√®me de filtrage avanc√© contre XSS et SQL Injection"""
    
    def __init__(self):
        # Patterns dangereux XSS - ENRICHIS
        self.xss_patterns = [
            r'<script[^>]*>.*?</script>',
            r'<script[^>]*>',
            r'</script>',
            r'javascript:',
            r'vbscript:',
            r'onload\s*=',
            r'onerror\s*=',
            r'onclick\s*=',
            r'onmouseover\s*=',
            r'onfocus\s*=',
            r'onblur\s*=',
            r'onchange\s*=',
            r'onsubmit\s*=',
            r'<iframe[^>]*>',
            r'<object[^>]*>',
            r'<embed[^>]*>',
            r'<form[^>]*>',
            r'<input[^>]*>',
            r'<meta[^>]*>',
            r'document\.cookie',
            r'document\.write',
            r'window\.location',
            r'eval\s*\(',
            r'setTimeout\s*\(',
            r'setInterval\s*\(',
            r'Function\s*\(',
            r'alert\s*\(',
            r'<svg[^>]*onload',
            r'<img[^>]*onerror',
            r'data:text/html',
            r'data:image/svg+xml'
        ]
        
        # Patterns dangereux SQL
        self.sql_patterns = [
            r'\b(union|select|insert|update|delete|drop|create|alter|exec|execute)\b',
            r'(\s|^)(or|and)\s+[\w\s]*\s*=\s*[\w\s]*',
            r'[\w\s]*\s*=\s*[\w\s]*\s+(or|and)\s+[\w\s]*',
            r';\s*(drop|delete|update|insert)',
            r'--\s*\w*',
            r'/\*.*?\*/',
            r'\'\s*(or|and)\s*\w*\s*=',
            r'"\s*(or|and)\s*\w*\s*=',
            r'\w*\s*=\s*\w*\s*(or|and)\s*1\s*=\s*1',
            r'(char|ascii|substring|concat|length)\s*\(',
            r'(information_schema|sysobjects|syscolumns)',
            r'0x[0-9a-f]+',
            r'benchmark\s*\(',
            r'sleep\s*\(',
            r'waitfor\s+delay',
            r'pg_sleep\s*\(',
            r'(load_file|into\s+outfile|into\s+dumpfile)'
        ]
        
        self.attack_log = []
        print("üõ°Ô∏è Filtrage XSS/SQL activ√© - Protection renforc√©e")

    def detect_xss(self, text: str) -> tuple:
        """D√©tecte les tentatives d'attaque XSS"""
        if not text:
            return False, []
        
        threats = []
        text_lower = text.lower()
        
        # V√©rification des patterns XSS
        for i, pattern in enumerate(self.xss_patterns, 1):
            if re.search(pattern, text_lower, re.IGNORECASE | re.DOTALL):
                threat_msg = f"XSS Pattern #{i} d√©tect√©: {pattern}"
                threats.append(threat_msg)
        
        return len(threats) > 0, threats

    def detect_sql_injection(self, text: str) -> tuple:
        """D√©tecte les tentatives d'injection SQL"""
        if not text:
            return False, []
        
        threats = []
        text_lower = text.lower()
        
        # V√©rification des patterns SQL
        for pattern in self.sql_patterns:
            if re.search(pattern, text_lower, re.IGNORECASE):
                threats.append(f"SQL Pattern d√©tect√©: {pattern}")
        
        return len(threats) > 0, threats

    def validate_and_filter(self, user_input: str) -> Dict[str, any]:
        """Validation compl√®te de l'input utilisateur"""
        result = {
            'original': user_input,
            'sanitized': user_input,
            'is_safe': True,
            'threats': [],
            'risk_level': 'LOW',
            'blocked': False
        }
        
        if not user_input:
            return result
        
        # D√©tection XSS
        xss_detected, xss_threats = self.detect_xss(user_input)
        if xss_detected:
            result['threats'].extend(xss_threats)
            result['is_safe'] = False
        
        # D√©tection SQL Injection
        sql_detected, sql_threats = self.detect_sql_injection(user_input)
        if sql_detected:
            result['threats'].extend(sql_threats)
            result['is_safe'] = False
        
        # Calcul du niveau de risque
        threat_count = len(result['threats'])
        if threat_count == 0:
            result['risk_level'] = 'LOW'
        elif threat_count <= 2:
            result['risk_level'] = 'MEDIUM'
        else:
            result['risk_level'] = 'HIGH'
        
        # D√©cision de blocage pour menaces HIGH
        if result['risk_level'] == 'HIGH' or threat_count > 3:
            result['blocked'] = True
            result['sanitized'] = '[INPUT BLOCKED - THREAT DETECTED]'
        
        return result

class SimpleSecureChatProtection:
    """Version simplifi√©e du syst√®me de s√©curit√©"""
    
    def __init__(self):
        self.session_id = secrets.token_hex(16)
        self.security_filter = SecurityFilter()
        self.enabled = True
        print(f"üîê Protection s√©curis√©e activ√©e - Session: {self.session_id}")

    def secure_message_validation(self, message):
        """Validation s√©curis√©e simplifi√©e"""
        if not message:
            return {"safe": True, "message": message, "warnings": []}
        
        # Filtrage s√©curit√©
        validation_result = self.security_filter.validate_and_filter(message)
        
        return {
            "safe": validation_result['is_safe'] and not validation_result['blocked'],
            "message": validation_result['sanitized'] if not validation_result['blocked'] else validation_result['message'],
            "original": validation_result['original'],
            "threats": validation_result['threats'],
            "risk_level": validation_result['risk_level'],
            "blocked": validation_result['blocked'],
            "warnings": validation_result['threats']
        }

def main():
    st.set_page_config(
        page_title="üöó AUTOSAR RAG Assistant",
        page_icon="üîê",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    st.title("üöó AUTOSAR RAG Assistant avec S√©curit√© Avanc√©e")
    st.markdown("### üîê Assistant s√©curis√© pour AUTOSAR et standards RFC")

    # Initialisation du syst√®me de s√©curit√©
    if "security" not in st.session_state:
        st.session_state.security = SimpleSecureChatProtection()

    # Initialisation RAG
    if "rag" not in st.session_state:
        with st.spinner("üîÑ Initialisation du syst√®me RAG AUTOSAR..."):
            st.session_state.rag = RAGRetriever()
        st.success("‚úÖ Syst√®me RAG AUTOSAR initialis√© avec succ√®s!")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Sidebar avec param√®tres
    with st.sidebar:
        st.header("‚öôÔ∏è Configuration")
        
        selected_model = st.selectbox(
            "ü§ñ Choisir le mod√®le",
            ["deepseek-r1:7b", "llama3.1:latest", "API Model (Gemini)"],
            index=0,
            help="S√©lectionnez le mod√®le pour g√©n√©rer les r√©ponses"
        )
        
        api_key = None
        if "API Model" in selected_model:
            api_key = st.text_input("üîë Cl√© API", type="password")
        
        temperature = st.slider("üå°Ô∏è Temp√©rature", 0.0, 1.0, 0.3, help="Contr√¥le la cr√©ativit√© des r√©ponses")
        
        # Statistiques RAG
        st.header("üìä Statistiques RAG")
        if hasattr(st.session_state, 'rag'):
            stats = st.session_state.rag.get_stats()
            st.metric("üìö Documents", stats['total_documents'])
            st.metric("üß© Chunks", stats['total_chunks'])
            st.metric("üß† Mod√®le", stats['embedding_model'])
        
        # S√©curit√©
        st.header("üõ°Ô∏è S√©curit√©")
        st.success("üîê Protection XSS/SQL : **ACTIVE**")
        st.success("üö´ Blocage automatique : **ACTIF**")
        
        # Gestion documents
        st.header("üìÅ Gestion Documents")
        uploaded_file = st.file_uploader(
            "üì§ Ajouter un document AUTOSAR",
            type=['txt', 'pdf', 'docx', 'md'],
            help="Ajoutez vos propres documents AUTOSAR"
        )
        
        if uploaded_file:
            if st.button("‚úÖ Ajouter au RAG"):
                with st.spinner("Traitement du document..."):
                    try:
                        # Sauvegarder le fichier
                        file_path = st.session_state.rag.documents_path / uploaded_file.name
                        with open(file_path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                        
                        # Reconstruire la base
                        st.session_state.rag._build_vector_database()
                        st.success(f"‚úÖ Document {uploaded_file.name} ajout√©!")
                        
                    except Exception as e:
                        st.error(f"‚ùå Erreur: {e}")

    # Interface de chat
    # Affichage des messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if message["role"] == "assistant" and st.session_state.security.enabled:
                st.caption("üîê R√©ponse s√©curis√©e bas√©e sur la base de connaissances AUTOSAR")

    # Input utilisateur avec validation s√©curis√©e
    if prompt := st.chat_input("üîê Posez votre question sur AUTOSAR ou les RFC..."):
        
        # Validation s√©curis√©e
        validation = st.session_state.security.secure_message_validation(prompt)
        
        if validation["blocked"]:
            st.error("üö´ **MESSAGE BLOQU√â** - Contenu potentiellement dangereux d√©tect√©")
            st.warning(f"**Niveau de menace :** {validation['risk_level']}")
            if validation["threats"]:
                with st.expander("‚ö†Ô∏è D√©tails des menaces"):
                    for threat in validation["threats"]:
                        st.write(f"‚Ä¢ {threat}")
            return
        
        # Message s√©curis√© - traitement normal
        if not validation["safe"]:
            st.warning(f"‚ö†Ô∏è Message nettoy√© ({len(validation['warnings'])} menaces supprim√©es)")
            processed_query = validation["message"]
        else:
            processed_query = prompt
        
        # Ajouter le message utilisateur
        st.session_state.messages.append({"role": "user", "content": processed_query})
        
        with st.chat_message("user"):
            st.markdown(processed_query)
        
        # G√©n√©rer la r√©ponse
        with st.chat_message("assistant"):
            with st.spinner("üîç Recherche dans la base AUTOSAR..."):
                
                # Recherche RAG
                start_time = time.time()
                chunks = st.session_state.rag.hybrid_search(processed_query, top_k=5)
                search_time = time.time() - start_time
                
                st.caption(f"üîç {len(chunks)} chunks trouv√©s en {search_time:.2f}s")
                
                # G√©n√©ration de la r√©ponse
                with st.spinner("ü§ñ G√©n√©ration de la r√©ponse..."):
                    answer = st.session_state.rag.generate_answer(
                        processed_query,
                        chunks,
                        model_type=selected_model,
                        api_key=api_key,
                        temperature=temperature
                    )
                
                # Affichage de la r√©ponse
                st.markdown(answer)
                
                if st.session_state.security.enabled:
                    st.caption("üîê R√©ponse s√©curis√©e bas√©e sur la base de connaissances AUTOSAR")
                
                # Sources utilis√©es
                if chunks:
                    with st.expander("üìö Sources consult√©es"):
                        for i, chunk in enumerate(chunks, 1):
                            st.write(f"**{i}. {chunk.metadata['source']}** ({chunk.metadata['word_count']} mots)")
                            with st.expander(f"Extrait {i}"):
                                st.text(chunk.content[:300] + "..." if len(chunk.content) > 300 else chunk.content)
                
                # Ajouter √† l'historique
                st.session_state.messages.append({"role": "assistant", "content": answer})

    # Section exemples
    with st.expander("üí° Exemples de questions"):
        st.markdown("""
        **Questions sur AUTOSAR :**
        - Qu'est-ce que l'architecture AUTOSAR ?
        - Comment fonctionne la pile de communication AUTOSAR ?
        - Qu'est-ce que le RTE dans AUTOSAR ?
        - Quels sont les composants du Basic Software (BSW) ?
        
        **Questions sur les RFC :**
        - Comment TCP est-il int√©gr√© dans AUTOSAR ?
        - Quel est le r√¥le d'UDP dans les communications automobiles ?
        - Comment AUTOSAR g√®re-t-il les protocoles IP ?
        
        **Questions sur la s√©curit√© :**
        - Quels sont les m√©canismes de s√©curit√© AUTOSAR ?
        - Comment fonctionne SecOC ?
        - Quelles sont les normes de cybers√©curit√© automotive ?
        """)

    # Footer avec informations syst√®me
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("üîê S√©curit√©", "ACTIVE")
    
    with col2:
        if hasattr(st.session_state, 'rag'):
            stats = st.session_state.rag.get_stats()
            st.metric("üìö Base RAG", f"{stats['total_chunks']} chunks")
    
    with col3:
        st.metric("üöó Focus", "AUTOSAR + RFC")

if __name__ == "__main__":
    main()